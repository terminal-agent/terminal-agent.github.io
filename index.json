[{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/terminal-agent/reptile\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ca href=\"https://github.com/terminal-agent/AnnotationGuidelines\" class=\"btn external\" target=\"_blank\"\u003eGUIDELINE\u003c/a\u003e\n\u003ca href=\"https://www.notion.so/On-Policy-SFT-Annotation-How-Minimal-Human-Edits-Unlock-Massive-Gains-in-LLM-Agents-2b80ba07baa880d6ba7fca50816d33f2\" class=\"btn external\" target=\"_blank\"\u003eNOTION-Version\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"1-the-need-for-a-fast-system-in-terminal-based-swe-data-collection\"\u003e1. The Need for a Fast System in Terminal-Based SWE Data Collection\u003c/h2\u003e\n\u003cp\u003eIn terminal-based SFT data collection for software engineering (SWE) tasks, system responsiveness is a crucial determinant of both data efficiency and data quality. For annotators who are not proficient with command-line interfaces, two fundamental issues—slow typing speed and difficulty recalling commands—create significant friction in the labeling process.\u003c/p\u003e\n\u003cp\u003eFirst, \u003cstrong\u003ethe interaction cost of terminal input is inherently high\u003c/strong\u003e. Unlike graphical interfaces that offer affordances such as buttons, menus, or auto-completion, \u003cem\u003eterminals rely entirely on textual command entry\u003c/em\u003e. Each operation requires the annotator to \u003cstrong\u003erecall and retype precise commands and parameters, often under the risk of syntax errors\u003c/strong\u003e. When annotators frequently make syntax or command errors due to limited terminal proficiency, the repeated cycles of editing, rerunning, and verifying become time-consuming and mentally exhausting, causing substantial inefficiency and fatigue throughout the labeling process.\u003c/p\u003e","title":"On Policy Annotation: Minimal Human Edits Unlock Massive Gains in LLM Agents"},{"summary":"\u003ca href=\"https://github.com/terminal-agent/reptile\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWe propose \u003cstrong\u003eReptile\u003c/strong\u003e, a terminal agent that operates under an extended \u003cstrong\u003eREPL (Read-Execute-Print-Learn Loop)\u003c/strong\u003e protocol, where human feedback is seamlessly integrated into the agent\u0026rsquo;s execution loop.\u003c/p\u003e\n\u003cp\u003eUnlike traditional REPL (Read-Execute-Print Loop) environments that focus solely on code evaluation, our REPL protocol emphasizes the iterative cycle of human-agent collaboration, transforming the terminal from a passive command executor into an interactive learning environment.\u003c/p\u003e\n\u003cfigure style=\"text-align: center; margin: 1rem 0;\"\u003e\n  \u003cimg src=\"https://hackmd.io/_uploads/SkGiD2BWWl.png\" style=\"width: 60%; display: block; margin: 0 auto;\"\u003e\n\u003c/figure\u003e\n\u003cp\u003eThis blog focus on \u003cstrong\u003eworkflow\u003c/strong\u003e and \u003cstrong\u003eevaluation\u003c/strong\u003e. We detail the \u003cstrong\u003eon-policy annotation\u003c/strong\u003e and \u003cstrong\u003eSFT training\u003c/strong\u003e in \u003ca href=\"https://terminal-agent.github.io/blog/annotation/\"\u003ehttps://terminal-agent.github.io/blog/annotation/\u003c/a\u003e.\u003c/p\u003e","title":"Reptile: Terminal-Agent with Human-in-the-loop Learning"},{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/sail-sg/tty-use\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ca href=\"https://x.com/mavenlin/status/1977758827366817929\" class=\"btn external\" target=\"_blank\"\u003eTWITTER\u003c/a\u003e\n\u003ca href=\"https://tinyurl.com/vrwcmpks\" class=\"btn external\" target=\"_blank\"\u003eNOTION-Version\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eLLM systems today are gravitating toward structured \u003cstrong\u003e“tool protocols”.\u003c/strong\u003e The most prominent of these, \u003cstrong\u003eMCP\u003c/strong\u003e, defines tools through JSON schemas that describe how models can interact with a computer. But here’s the quiet irony: models already know. They’ve seen countless examples of people running commands, inspecting logs, and fixing errors — all through a single interface that’s existed for half a century: the \u003cstrong\u003eterminal\u003c/strong\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"the-burden-of-new-protocols\"\u003eThe burden of new protocols\u003c/h3\u003e\n\u003cp\u003eModern tool frameworks like MCP describe every action in meticulous JSON. They are explicit, structured and heavy. To use them, an endless catalog of tool descriptions need to be maintained and explained in the system prompt.\u003c/p\u003e","title":"Terminal: LLM’s Last Tool"}]